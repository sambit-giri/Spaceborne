{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_cores)\n",
    "os.environ['NUMBA_NUM_THREADS'] = str(num_cores)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import gc\n",
    "import yaml\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator\n",
    "\n",
    "import spaceborne.ell_utils as ell_utils\n",
    "import spaceborne.cl_preprocessing as cl_utils\n",
    "import spaceborne.covariance as covmat_utils\n",
    "import spaceborne.fisher_matrix as fm_utils\n",
    "import spaceborne.my_module as mm\n",
    "import spaceborne.cosmo_lib as cosmo_lib\n",
    "import spaceborne.wf_cl_lib as wf_cl_lib\n",
    "import spaceborne.pyccl_interface as pyccl_interface\n",
    "import spaceborne.sigma2_SSC as sigma2_SSC\n",
    "import spaceborne.onecovariance_interface as oc_interface\n",
    "import spaceborne.config_checker as config_checker\n",
    "import spaceborne.responses as responses\n",
    "\n",
    "script_start_time = time.perf_counter()\n",
    "# TODO restore this\n",
    "# ROOT = os.getcwd()\n",
    "ROOT = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400bfce",
   "metadata": {},
   "source": [
    "#### General settings\n",
    "Specify the path of the configuration YAML file (default is `ROOT/example_cfg.yaml`) and shorten variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53349fe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# if you want to run without arguments\n",
    "with open('example_cfg.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# define dictionaries corresponding to the relevant sections\n",
    "general_cfg = cfg['general_cfg']\n",
    "covariance_cfg = cfg['covariance_cfg']\n",
    "fm_cfg = cfg['FM_cfg']\n",
    "pyccl_cfg = covariance_cfg['PyCCL_cfg']\n",
    "fid_pars_dict = cfg['cosmology']\n",
    "\n",
    "# TODO delete useless ones!!\n",
    "# some convenence variables, just to make things more readable\n",
    "zbins = general_cfg['zbins']\n",
    "ep_or_ed = general_cfg['EP_or_ED']\n",
    "ell_max_WL = general_cfg['ell_max_WL']\n",
    "ell_max_GC = general_cfg['ell_max_GC']\n",
    "ell_max_3x2pt = general_cfg['ell_max_3x2pt']\n",
    "center_or_min = general_cfg['center_or_min']\n",
    "triu_tril = covariance_cfg['triu_tril']\n",
    "row_col_major = covariance_cfg['row_col_major']\n",
    "gl_or_lg = covariance_cfg['GL_or_LG']\n",
    "n_probes = general_cfg['n_probes']\n",
    "bnt_transform = general_cfg['BNT_transform']\n",
    "shift_nz_interpolation_kind = covariance_cfg['shift_nz_interpolation_kind']\n",
    "nz_gaussian_smoothing = covariance_cfg['nz_gaussian_smoothing']  # does not seem to have a large effect...\n",
    "nz_gaussian_smoothing_sigma = covariance_cfg['nz_gaussian_smoothing_sigma']\n",
    "shift_nz = covariance_cfg['shift_nz']\n",
    "normalize_shifted_nz = covariance_cfg['normalize_shifted_nz']\n",
    "compute_bnt_with_shifted_nz_for_zcuts = covariance_cfg['compute_bnt_with_shifted_nz_for_zcuts']\n",
    "include_ia_in_bnt_kernel_for_zcuts = covariance_cfg['include_ia_in_bnt_kernel_for_zcuts']\n",
    "nbl_WL_opt = general_cfg['nbl_WL_opt']\n",
    "covariance_ordering_2D = covariance_cfg['covariance_ordering_2D']\n",
    "magcut_lens = general_cfg['magcut_lens']\n",
    "magcut_source = general_cfg['magcut_source']\n",
    "use_h_units = general_cfg['use_h_units']\n",
    "covariance_cfg['probe_ordering'] = (('L', 'L'), (gl_or_lg[0], gl_or_lg[1]), ('G', 'G'))\n",
    "probe_ordering = covariance_cfg['probe_ordering']\n",
    "which_pk = general_cfg['which_pk']\n",
    "which_ng_cov_suffix = 'G' + ''.join(covariance_cfg[covariance_cfg['ng_cov_code'] + '_cfg']['which_ng_cov'])\n",
    "flat_fid_pars_dict = mm.flatten_dict(fid_pars_dict)\n",
    "h = flat_fid_pars_dict['h']\n",
    "\n",
    "# load some nuisance parameters\n",
    "# note that zbin_centers is not exactly equal to the result of wf_cl_lib.get_z_mean...\n",
    "# TODO what are these needed for?? It used to be to compute bias at this points...\n",
    "# zbin_centers_src = cfg['covariance_cfg']['zbin_centers_src']\n",
    "# zbin_centers_lns = cfg['covariance_cfg']['zbin_centers_lns']\n",
    "ngal_src = cfg['covariance_cfg']['ngal_lensing']\n",
    "ngal_lns = cfg['covariance_cfg']['ngal_clustering']\n",
    "galaxy_bias_fit_fiducials = np.array([fid_pars_dict['FM_ordered_params'][f'bG{zi:02d}'] for zi in range(1, 5)])\n",
    "magnification_bias_fit_fiducials = np.array([fid_pars_dict['FM_ordered_params'][f'bM{zi:02d}'] for zi in range(1, 5)])\n",
    "dzWL_fiducial = np.array([fid_pars_dict['FM_ordered_params'][f'dzWL{zi:02d}'] for zi in range(1, zbins + 1)])\n",
    "dzGC_fiducial = np.array([fid_pars_dict['FM_ordered_params'][f'dzWL{zi:02d}'] for zi in range(1, zbins + 1)])\n",
    "\n",
    "# TODO remove this, pull from the DR1 branch!\n",
    "assert np.all(dzWL_fiducial == dzGC_fiducial), 'dzWL and dzGC shifts do not match'\n",
    "warnings.warn('dzGC_fiducial are equal to dzWL_fiducial')\n",
    "\n",
    "clr = cm.rainbow(np.linspace(0, 1, zbins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ca24e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# define grid to compute the various quantities entering the SSC integrand\n",
    "z_grid_ssc_integrands = np.linspace(covariance_cfg['Spaceborne_cfg']['z_min_ssc_integrands'],\n",
    "                                    covariance_cfg['Spaceborne_cfg']['z_max_ssc_integrands'],\n",
    "                                    covariance_cfg['Spaceborne_cfg']['z_steps_ssc_integrands'])\n",
    "\n",
    "# some checks on the configurations\n",
    "config_checker_obj = config_checker.SpaceborneConfigChecker(cfg)\n",
    "k_txt_label, pk_txt_label = config_checker_obj.run_all_checks()\n",
    "\n",
    "# instantiate CCL object\n",
    "ccl_obj = pyccl_interface.PycclClass(fid_pars_dict)\n",
    "\n",
    "# build array to compress/decompress the Cl/covariance indices and store it into the covariance dictionary\n",
    "ind = mm.build_full_ind(triu_tril, row_col_major, zbins)\n",
    "covariance_cfg['ind'] = ind\n",
    "zpairs_auto, zpairs_cross, zpairs_3x2pt = mm.get_zpairs(zbins)\n",
    "ind_auto = ind[:zpairs_auto, :].copy()\n",
    "ind_cross = ind[zpairs_auto:zpairs_cross + zpairs_auto, :].copy()\n",
    "ind_dict = {('L', 'L'): ind_auto,\n",
    "            ('G', 'L'): ind_cross,\n",
    "            ('G', 'G'): ind_auto}\n",
    "covariance_cfg['ind_dict'] = ind_dict\n",
    "\n",
    "# TODO remove this!\n",
    "if not general_cfg['ell_cuts']:\n",
    "    kmax_h_over_Mpc = general_cfg['kmax_h_over_Mpc_ref']\n",
    "else:\n",
    "    general_cfg['ell_cuts_subfolder'] = f'{general_cfg[\"which_cuts\"]}/ell_{general_cfg[\"center_or_min\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c2353",
   "metadata": {},
   "source": [
    "#### Compute number of ell bins, $\\ell$ values, $\\Delta\\ell$ and corresponding edges\n",
    "This is done by taking a reference binning (the default case is 32 logarithmically-equispaced bins in the $\\ell$ range $[10, 5000]$) and then cutting the number of bins for the different probes depending on the desired $\\ell_{\\rm max}$.\n",
    "\n",
    "As an example, a $\\ell_{\\rm max}^{\\rm WL} = 3000$ will fall in the 29th of the 32 above-mentioned bins, so WL will have 29 bins, but with the same centers and edges of the reference case\n",
    "\n",
    "TODO remove wadd???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35b53a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# compute ell and delta ell values in the reference (optimistic) case\n",
    "ell_ref_nbl32, delta_l_ref_nbl32, ell_edges_ref_nbl32 = (\n",
    "    ell_utils.compute_ells(general_cfg['nbl_WL_opt'], general_cfg['ell_min'], general_cfg['ell_max_WL_opt'],\n",
    "                           recipe='ISTF', output_ell_bin_edges=True))\n",
    "\n",
    "# perform the cuts (not the redshift-dependent ones!) on the ell centers and edges\n",
    "ell_dict = {}\n",
    "ell_dict['ell_WL'] = np.copy(ell_ref_nbl32[ell_ref_nbl32 < ell_max_WL])\n",
    "ell_dict['ell_GC'] = np.copy(ell_ref_nbl32[ell_ref_nbl32 < ell_max_GC])\n",
    "ell_dict['ell_3x2pt'] = np.copy(ell_ref_nbl32[ell_ref_nbl32 < ell_max_3x2pt])\n",
    "ell_dict['ell_WA'] = np.copy(ell_ref_nbl32[(ell_ref_nbl32 > ell_max_GC) & (ell_ref_nbl32 < ell_max_WL)])\n",
    "ell_dict['ell_XC'] = np.copy(ell_dict['ell_3x2pt'])\n",
    "\n",
    "# store edges *except last one for dimensional consistency* in the ell_dict\n",
    "ell_dict['ell_edges_WL'] = np.copy(ell_edges_ref_nbl32[ell_edges_ref_nbl32 < ell_max_WL])[:-1]\n",
    "ell_dict['ell_edges_GC'] = np.copy(ell_edges_ref_nbl32[ell_edges_ref_nbl32 < ell_max_GC])[:-1]\n",
    "ell_dict['ell_edges_3x2pt'] = np.copy(ell_edges_ref_nbl32[ell_edges_ref_nbl32 < ell_max_3x2pt])[:-1]\n",
    "ell_dict['ell_edges_XC'] = np.copy(ell_dict['ell_edges_3x2pt'])\n",
    "ell_dict['ell_edges_WA'] = np.copy(\n",
    "    ell_edges_ref_nbl32[(ell_edges_ref_nbl32 > ell_max_GC) & (ell_edges_ref_nbl32 < ell_max_WL)])[:-1]\n",
    "\n",
    "for key in ell_dict.keys():\n",
    "    if ell_dict[key].size > 0:  # Check if the array is non-empty\n",
    "        assert np.max(ell_dict[key]) > 15, f'ell values for key {key} must *not* be in log space'\n",
    "\n",
    "# set the corresponding number of ell bins\n",
    "nbl_WL = len(ell_dict['ell_WL'])\n",
    "nbl_GC = len(ell_dict['ell_GC'])\n",
    "nbl_WA = len(ell_dict['ell_WA'])\n",
    "nbl_3x2pt = nbl_GC\n",
    "\n",
    "assert len(ell_dict['ell_3x2pt']) == len(ell_dict['ell_XC']) == len(ell_dict['ell_GC']), '3x2pt, XC and GC should '\\\n",
    "    ' have the same number of ell bins'\n",
    "assert np.all(ell_dict['ell_3x2pt'] == ell_dict['ell_XC']), '3x2pt and XC should have the same ell values'\n",
    "assert np.all(ell_dict['ell_3x2pt'] == ell_dict['ell_GC']), '3x2pt and GC should have the same ell values'\n",
    "\n",
    "# TODO the main should not change the cfg\n",
    "print('$\\\\ell_min$, $\\\\ell_max$, number of ell bins for the different probes:')\n",
    "print(f'WL: {general_cfg[\"ell_min\"]}, {ell_max_WL}, {nbl_WL}')\n",
    "print(f'GCph: {general_cfg[\"ell_min\"]}, {ell_max_GC}, {nbl_GC}')\n",
    "print(f'3x2pt: {general_cfg[\"ell_min\"]}, {ell_max_3x2pt}, {nbl_3x2pt}')\n",
    "general_cfg['nbl_WL'] = nbl_WL\n",
    "general_cfg['nbl_GC'] = nbl_GC\n",
    "general_cfg['nbl_3x2pt'] = nbl_3x2pt\n",
    "\n",
    "\n",
    "# TODO remove this\n",
    "assert nbl_WL == nbl_3x2pt == nbl_GC, 'use the same number of bins for the moment'\n",
    "\n",
    "delta_dict = {'delta_l_WL': np.copy(delta_l_ref_nbl32[:nbl_WL]),\n",
    "              'delta_l_GC': np.copy(delta_l_ref_nbl32[:nbl_GC]),\n",
    "              'delta_l_WA': np.copy(delta_l_ref_nbl32[nbl_GC:nbl_WL])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove this?\n",
    "# this is just to make the .format() more compact\n",
    "variable_specs = {'EP_or_ED': ep_or_ed,\n",
    "                  'ep_or_ed': ep_or_ed,\n",
    "                  'zbins': zbins,\n",
    "                  'ell_max_WL': ell_max_WL, 'ell_max_GC': ell_max_GC, 'ell_max_3x2pt': ell_max_3x2pt,\n",
    "                  'nbl_WL': nbl_WL, 'nbl_GC': nbl_GC, 'nbl_WA': nbl_WA, 'nbl_3x2pt': nbl_3x2pt,\n",
    "                  'kmax_h_over_Mpc': kmax_h_over_Mpc, 'center_or_min': center_or_min,\n",
    "                  'BNT_transform': bnt_transform,\n",
    "                  'which_ng_cov': which_ng_cov_suffix,\n",
    "                  'ng_cov_code': covariance_cfg['ng_cov_code'],\n",
    "                  'magcut_lens': magcut_lens,\n",
    "                  'magcut_source': magcut_source,\n",
    "                  'zmin_nz_lens': general_cfg['zmin_nz_lens'],\n",
    "                  'zmin_nz_source': general_cfg['zmin_nz_source'],\n",
    "                  'zmax_nz': general_cfg['zmax_nz'],\n",
    "                  'which_pk': which_pk,\n",
    "                  'flat_or_nonflat': general_cfg['flat_or_nonflat'],\n",
    "                  'flagship_version': general_cfg['flagship_version'],\n",
    "                  }\n",
    "print('variable_specs:\\n')\n",
    "print(variable_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792faa9",
   "metadata": {},
   "source": [
    "#### Import redshift distribution, $n(z)$\n",
    "The shape of the input file should be `(zpoints, zbins + 1)`, with `zpoints` the number of points over which the distribution is measured and zbins the number of redshift bins. The first column should contain the redshifts values.\n",
    "\n",
    "We also define:\n",
    "- `n_of_z_full`: nz table including a column for the z values\n",
    "- `n_of_z`:      nz table excluding a column for the z values\n",
    "- `n_of_z_original`: nz table as imported (it may be subjected to shifts later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nz_src_full = np.genfromtxt(covariance_cfg[\"nz_sources_filename\"])\n",
    "nz_lns_full = np.genfromtxt(covariance_cfg[\"nz_lenses_filename\"])\n",
    "\n",
    "assert nz_src_full.shape[1] == zbins + 1, 'n_of_z must have zbins + 1 columns; the first one must be for the z values'\n",
    "assert nz_lns_full.shape[1] == zbins + 1, 'n_of_z must have zbins + 1 columns; the first one must be for the z values'\n",
    "\n",
    "zgrid_nz_src = nz_src_full[:, 0]\n",
    "zgrid_nz_lns = nz_lns_full[:, 0]\n",
    "nz_src = nz_src_full[:, 1:]\n",
    "nz_lns = nz_lns_full[:, 1:]\n",
    "\n",
    "# nz may be subjected to a shift\n",
    "nz_unshifted_src = nz_src\n",
    "nz_unshifted_lns = nz_lns\n",
    "\n",
    "wf_cl_lib.plot_nz_src_lns(zgrid_nz_src, nz_src, zgrid_nz_lns, nz_lns, colors=clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35933e",
   "metadata": {},
   "source": [
    "#### Compute scale cuts\n",
    "In order to do this, we need to:\n",
    "1. Compute the BNT. This is done with the raw, or unshifted n(z), but only for the purpose of computing the\n",
    "    $\\ell$ cuts - the rest of the code uses a BNT matrix from the shifted $n(z)$ - see also comment below.\n",
    "2. Compute the kernels for the un-shifted $n(z)$ (for consistency)\n",
    "3. BNT-transform these kernels (for lensing, it's only the gamma kernel)\n",
    "4. Compute the effective redshift as first moment of the (BNT-transformed) kernel\n",
    "5. Compute redshift-dependent $\\ell$ cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5da6d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 1. Compute BNT\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "assert compute_bnt_with_shifted_nz_for_zcuts is False, 'The BNT used to compute the z_means and ell cuts is just for a simple case: no IA, no dz shift'\n",
    "assert shift_nz is True, 'The signal (and BNT used to transform it) is computed with a shifted n(z); You could use an un-shifted n(z) for the BNT, but' \\\n",
    "    'this would be slightly inconsistent (but also what I did so far).'\n",
    "assert include_ia_in_bnt_kernel_for_zcuts is False, 'We compute the BNT just for a simple case: no IA, no shift. This is because we want' \\\n",
    "                                                    ' to compute the z means'\n",
    "\n",
    "# * IMPORTANT NOTE: The BNT should be computed from the same n(z) (shifted or not) which is then used to compute\n",
    "# * the kernels which are then used to get the z_means, and finally the ell_cuts, for consistency. In other words,\n",
    "# * we cannot compute the kernels with a shifted n(z) and transform them with a BNT computed from the unshifted n(z)\n",
    "# * and viceversa. If the n(z) are shifted, one of the BNT kernels will become negative, but this is just because\n",
    "# * two of the original kernels get very close after the shift: the transformation is correct.\n",
    "# * Having said that, I leave the code below in case we want to change this in the future\n",
    "if nz_gaussian_smoothing:\n",
    "    nz_src = wf_cl_lib.gaussian_smmothing_nz(zgrid_nz_src, nz_unshifted_src, nz_gaussian_smoothing_sigma, plot=True)\n",
    "    nz_lns = wf_cl_lib.gaussian_smmothing_nz(zgrid_nz_lns, nz_unshifted_lns, nz_gaussian_smoothing_sigma, plot=True)\n",
    "if compute_bnt_with_shifted_nz_for_zcuts:\n",
    "    nz_src = wf_cl_lib.shift_nz(zgrid_nz_src, nz_unshifted_src, dzWL_fiducial, normalize=normalize_shifted_nz,\n",
    "                                plot_nz=False, interpolation_kind=shift_nz_interpolation_kind)\n",
    "    nz_lns = wf_cl_lib.shift_nz(zgrid_nz_lns, nz_unshifted_lns, dzGC_fiducial, normalize=normalize_shifted_nz,\n",
    "                                plot_nz=False, interpolation_kind=shift_nz_interpolation_kind)\n",
    "\n",
    "bnt_matrix = covmat_utils.compute_BNT_matrix(\n",
    "    zbins, zgrid_nz_src, nz_src, cosmo_ccl=ccl_obj.cosmo_ccl, plot_nz=False)\n",
    "\n",
    "# 2. compute the kernels for the un-shifted n(z) (for consistency)\n",
    "ccl_obj.zbins = zbins\n",
    "ccl_obj.set_nz(nz_full_src=np.hstack((zgrid_nz_src[:, None], nz_src)),\n",
    "               nz_full_lns=np.hstack((zgrid_nz_lns[:, None], nz_lns)))\n",
    "ccl_obj.check_nz_tuple(zbins)\n",
    "ccl_obj.set_ia_bias_tuple(z_grid_src=z_grid_ssc_integrands, has_ia=general_cfg['has_ia'])\n",
    "\n",
    "# set galaxy bias\n",
    "if general_cfg['which_forecast'] == 'SPV3':\n",
    "    ccl_obj.set_gal_bias_tuple_spv3(z_grid_lns=z_grid_ssc_integrands,\n",
    "                                    magcut_lens=magcut_lens / 10,\n",
    "                                    poly_fit_values=None)\n",
    "\n",
    "elif general_cfg['which_forecast'] == 'ISTF':\n",
    "    bias_func_str = general_cfg['bias_function']\n",
    "    bias_model = general_cfg['bias_model']\n",
    "    ccl_obj.set_gal_bias_tuple_istf(z_grid_lns=z_grid_ssc_integrands,\n",
    "                                    bias_function_str=bias_func_str,\n",
    "                                    bias_model=bias_model)\n",
    "\n",
    "# set magnification bias\n",
    "ccl_obj.set_mag_bias_tuple(z_grid_lns=z_grid_ssc_integrands,\n",
    "                           has_magnification_bias=general_cfg['has_magnification_bias'],\n",
    "                           magcut_lens=magcut_lens / 10,\n",
    "                           poly_fit_values=None)\n",
    "\n",
    "# set Pk\n",
    "ccl_obj.p_of_k_a = 'delta_matter:delta_matter'\n",
    "\n",
    "# set kernel arrays and objects\n",
    "ccl_obj.set_kernel_obj(general_cfg['has_rsd'], covariance_cfg['PyCCL_cfg']['n_samples_wf'])\n",
    "ccl_obj.set_kernel_arr(z_grid_wf=z_grid_ssc_integrands,\n",
    "                       has_magnification_bias=general_cfg['has_magnification_bias'])\n",
    "\n",
    "if general_cfg['which_forecast'] == 'SPV3':\n",
    "    gal_kernel_plt_title = 'galaxy kernel\\n(w/o gal bias!)'\n",
    "    ccl_obj.wf_galaxy_arr = ccl_obj.wf_galaxy_wo_gal_bias_arr\n",
    "\n",
    "if general_cfg['which_forecast'] == 'ISTF':\n",
    "    gal_kernel_plt_title = 'galaxy kernel\\n(w/ gal bias)'\n",
    "    ccl_obj.wf_galaxy_arr = ccl_obj.wf_galaxy_w_gal_bias_arr\n",
    "\n",
    "# 3. bnt-transform these kernels (for lensing, it's only the gamma kernel, without IA)\n",
    "wf_gamma_ccl_bnt = (bnt_matrix @ ccl_obj.wf_gamma_arr.T).T\n",
    "\n",
    "# 4. compute the z means\n",
    "z_means_ll = wf_cl_lib.get_z_means(z_grid_ssc_integrands, ccl_obj.wf_gamma_arr)\n",
    "z_means_gg = wf_cl_lib.get_z_means(z_grid_ssc_integrands, ccl_obj.wf_galaxy_arr)\n",
    "z_means_ll_bnt = wf_cl_lib.get_z_means(z_grid_ssc_integrands, wf_gamma_ccl_bnt)\n",
    "\n",
    "plt.figure()\n",
    "for zi in range(zbins):\n",
    "    plt.plot(z_grid_ssc_integrands, ccl_obj.wf_gamma_arr[:, zi], ls='-', c=clr[zi])\n",
    "    plt.plot(z_grid_ssc_integrands, wf_gamma_ccl_bnt[:, zi], ls='--', c=clr[zi])\n",
    "    plt.axvline(z_means_ll_bnt[zi], ls=':', c=clr[zi])\n",
    "\n",
    "# Create custom legend entries with black color\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='black', ls='-', label='wf_gamma_ccl'),\n",
    "    Line2D([0], [0], color='black', ls='--', label='wf_gamma_ccl_BNT'),\n",
    "    Line2D([0], [0], color='black', ls=':', label='z means BNT')\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel(r'$W_i^{\\gamma}(z)$')\n",
    "\n",
    "# assert np.all(np.diff(z_means_ll) > 0), 'z_means_ll should be monotonically increasing'\n",
    "# assert np.all(np.diff(z_means_gg) > 0), 'z_means_gg should be monotonically increasing'\n",
    "# assert np.all(np.diff(z_means_ll_bnt) > 0), ('z_means_ll_bnt should be monotonically increasing '\n",
    "#                                             '(not a strict condition, valid only if we do not shift the n(z) in this part)')\n",
    "\n",
    "# 5. compute the ell cuts\n",
    "ell_cuts_dict = {}\n",
    "ell_cuts_dict['LL'] = ell_utils.load_ell_cuts(\n",
    "    kmax_h_over_Mpc, z_means_ll_bnt, z_means_ll_bnt, ccl_obj.cosmo_ccl, zbins, h, general_cfg)\n",
    "ell_cuts_dict['GG'] = ell_utils.load_ell_cuts(\n",
    "    kmax_h_over_Mpc, z_means_gg, z_means_gg, ccl_obj.cosmo_ccl, zbins, h, general_cfg)\n",
    "ell_cuts_dict['GL'] = ell_utils.load_ell_cuts(\n",
    "    kmax_h_over_Mpc, z_means_gg, z_means_ll_bnt, ccl_obj.cosmo_ccl, zbins, h, general_cfg)\n",
    "ell_cuts_dict['LG'] = ell_utils.load_ell_cuts(\n",
    "    kmax_h_over_Mpc, z_means_ll_bnt, z_means_gg, ccl_obj.cosmo_ccl, zbins, h, general_cfg)\n",
    "ell_dict['ell_cuts_dict'] = ell_cuts_dict  # this is to pass the ll cuts to the covariance module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b613a7c",
   "metadata": {},
   "source": [
    "Now compute the BNT used for the rest of the code, i.e., with the same n(z) used in the rest of the code (i.e., shifted or un-shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc93642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shift_nz:\n",
    "    nz_src = wf_cl_lib.shift_nz(zgrid_nz_src, nz_unshifted_src, dzWL_fiducial, normalize=normalize_shifted_nz,\n",
    "                                plot_nz=False, interpolation_kind=shift_nz_interpolation_kind)\n",
    "    nz_lns = wf_cl_lib.shift_nz(zgrid_nz_lns, nz_unshifted_lns, dzGC_fiducial, normalize=normalize_shifted_nz,\n",
    "                                plot_nz=False, interpolation_kind=shift_nz_interpolation_kind)\n",
    "    # * this is important: the BNT matrix I use for the rest of the code (so not to compute the ell cuts) is instead\n",
    "    # * consistent with the shifted n(z) used to compute the kernels\n",
    "    bnt_matrix = covmat_utils.compute_BNT_matrix(\n",
    "        zbins, zgrid_nz_src, nz_src, cosmo_ccl=ccl_obj.cosmo_ccl, plot_nz=False)\n",
    "\n",
    "\n",
    "wf_cl_lib.plot_nz_src_lns(zgrid_nz_src, nz_src, zgrid_nz_lns, nz_lns, colors=clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# re-set n(z) used in CCL class, then re-compute kernels\n",
    "ccl_obj.set_nz(nz_full_src=np.hstack((zgrid_nz_src[:, None], nz_src)),\n",
    "               nz_full_lns=np.hstack((zgrid_nz_lns[:, None], nz_lns)))\n",
    "ccl_obj.set_kernel_obj(general_cfg['has_rsd'], covariance_cfg['PyCCL_cfg']['n_samples_wf'])\n",
    "ccl_obj.set_kernel_arr(z_grid_wf=z_grid_ssc_integrands,\n",
    "                       has_magnification_bias=general_cfg['has_magnification_bias'])\n",
    "\n",
    "if general_cfg['which_forecast'] == 'SPV3':\n",
    "    gal_kernel_plt_title = 'galaxy\\n(excl. gal. bias)'\n",
    "    ccl_obj.wf_galaxy_arr = ccl_obj.wf_galaxy_wo_gal_bias_arr\n",
    "\n",
    "if general_cfg['which_forecast'] == 'ISTF':\n",
    "    gal_kernel_plt_title = 'galaxy\\n(incl. gal. bias)'\n",
    "    ccl_obj.wf_galaxy_arr = ccl_obj.wf_galaxy_w_gal_bias_arr\n",
    "\n",
    "\n",
    "wf_names_list = ['delta', 'gamma', 'ia', 'magnification', 'lensing', gal_kernel_plt_title]\n",
    "wf_ccl_list = [ccl_obj.wf_delta_arr, ccl_obj.wf_gamma_arr, ccl_obj.wf_ia_arr, ccl_obj.wf_mu_arr,\n",
    "               ccl_obj.wf_lensing_arr, ccl_obj.wf_galaxy_arr]\n",
    "\n",
    "# plot\n",
    "for wf_idx in range(len(wf_ccl_list)):\n",
    "\n",
    "    plt.figure()\n",
    "    for zi in range(zbins):\n",
    "        plt.plot(z_grid_ssc_integrands, wf_ccl_list[wf_idx][:, zi], ls=\"-\", c=clr[zi], label=r'$z_{%d}$' % (zi + 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$W_i(z)$')\n",
    "    plt.legend()\n",
    "    plt.title(f'{wf_names_list[wf_idx]}')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434abab",
   "metadata": {},
   "source": [
    "#### Compute $C_\\ell$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compute cls\n",
    "ccl_obj.cl_ll_3d = ccl_obj.compute_cls(ell_dict['ell_WL'], ccl_obj.p_of_k_a,\n",
    "                                       ccl_obj.wf_lensing_obj, ccl_obj.wf_lensing_obj, 'spline')\n",
    "ccl_obj.cl_gl_3d = ccl_obj.compute_cls(ell_dict['ell_XC'], ccl_obj.p_of_k_a,\n",
    "                                       ccl_obj.wf_galaxy_obj, ccl_obj.wf_lensing_obj, 'spline')\n",
    "ccl_obj.cl_gg_3d = ccl_obj.compute_cls(ell_dict['ell_GC'], ccl_obj.p_of_k_a,\n",
    "                                       ccl_obj.wf_galaxy_obj, ccl_obj.wf_galaxy_obj, 'spline')\n",
    "ccl_obj.cl_wa_3d = ccl_obj.cl_ll_3d[nbl_3x2pt:nbl_WL]\n",
    "\n",
    "ccl_obj.cl_3x2pt_5d = np.zeros((n_probes, n_probes, nbl_3x2pt, zbins, zbins))\n",
    "ccl_obj.cl_3x2pt_5d[0, 0, :, :, :] = ccl_obj.cl_ll_3d[:nbl_3x2pt, :, :]\n",
    "ccl_obj.cl_3x2pt_5d[1, 0, :, :, :] = ccl_obj.cl_gl_3d[:nbl_3x2pt, :, :]\n",
    "ccl_obj.cl_3x2pt_5d[0, 1, :, :, :] = ccl_obj.cl_gl_3d[:nbl_3x2pt, :, :].transpose(0, 2, 1)\n",
    "ccl_obj.cl_3x2pt_5d[1, 1, :, :, :] = ccl_obj.cl_gg_3d[:nbl_3x2pt, :, :]\n",
    "\n",
    "cl_ll_3d, cl_gl_3d, cl_gg_3d, cl_wa_3d = ccl_obj.cl_ll_3d, ccl_obj.cl_gl_3d, ccl_obj.cl_gg_3d, ccl_obj.cl_wa_3d\n",
    "cl_3x2pt_5d = ccl_obj.cl_3x2pt_5d\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(13, 5))\n",
    "plt.tight_layout()\n",
    "for zi in range(zbins):\n",
    "    zj = zi\n",
    "    ax[0].loglog(ell_dict['ell_WL'], cl_ll_3d[:, zi, zj], c=clr[zi], label=r'$z_{%d}$' % (zi + 1))\n",
    "    ax[1].loglog(ell_dict['ell_XC'], cl_gl_3d[:, zi, zj], c=clr[zi])\n",
    "    ax[2].loglog(ell_dict['ell_GC'], cl_gg_3d[:, zi, zj], c=clr[zi])\n",
    "\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[2].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_ylabel(r'$C^{ii}_{\\ell}$')\n",
    "ax[0].set_title('LL')\n",
    "ax[1].set_title('GL')\n",
    "ax[2].set_title('GG')\n",
    "\n",
    "# Add overall legend on top\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.16), ncol=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c0a69",
   "metadata": {},
   "source": [
    "### Super-sample covariance\n",
    "Compute SSC; this is possible with Spaceborne, OneCovariance or CCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaceborne\n",
    "cov_folder_sb = covariance_cfg['Spaceborne_cfg']['cov_path']\n",
    "cov_sb_filename = covariance_cfg['Spaceborne_cfg']['cov_filename']\n",
    "variable_specs['ng_cov_code'] = covariance_cfg['ng_cov_code']\n",
    "variable_specs['which_ng_cov'] = which_ng_cov_suffix\n",
    "include_b2 = covariance_cfg['Spaceborne_cfg']['include_b2']\n",
    "\n",
    "if 'cNG' in covariance_cfg['Spaceborne_cfg']['which_ng_cov']:\n",
    "    raise NotImplementedError('You should review the which_ng_cov arg in the cov_filename formatting above, \"SSC\" is'\n",
    "                              'hardcoded at the moment')\n",
    "\n",
    "if covariance_cfg['ng_cov_code'] == 'Spaceborne':\n",
    "    print('Start SSC computation with Spaceborne...')\n",
    "\n",
    "    if covariance_cfg['Spaceborne_cfg']['which_pk_responses'] == 'halo_model':\n",
    "\n",
    "        # ! 1. Get halo model responses from CCL\n",
    "        ccl_obj.initialize_trispectrum(which_ng_cov='SSC', probe_ordering=probe_ordering,\n",
    "                                       pyccl_cfg=pyccl_cfg, which_pk='_')\n",
    "\n",
    "        # k and z grids (responses will be interpolated below)\n",
    "        k_grid_resp = ccl_obj.responses_dict['L', 'L', 'L', 'L']['k_1overMpc']\n",
    "        a_grid_resp = ccl_obj.responses_dict['L', 'L', 'L', 'L']['a_arr']\n",
    "        # translate a to z and cut the arrays to the maximum redshift of the SU responses (much smaller range!)\n",
    "        z_grid_resp = cosmo_lib.a_to_z(a_grid_resp)[::-1]\n",
    "\n",
    "        dPmm_ddeltab = ccl_obj.responses_dict['L', 'L', 'L', 'L']['dpk12']\n",
    "        dPgm_ddeltab = ccl_obj.responses_dict['L', 'L', 'G', 'L']['dpk34']\n",
    "        dPgg_ddeltab = ccl_obj.responses_dict['G', 'G', 'G', 'G']['dpk12']\n",
    "\n",
    "        # a is flipped w.r.t. z\n",
    "        dPmm_ddeltab_hm = np.flip(dPmm_ddeltab, axis=1)\n",
    "        dPgm_ddeltab_hm = np.flip(dPgm_ddeltab, axis=1)\n",
    "        dPgg_ddeltab_hm = np.flip(dPgg_ddeltab, axis=1)\n",
    "\n",
    "        # quick sanity check\n",
    "        assert np.allclose(ccl_obj.responses_dict['L', 'L', 'G', 'L']['dpk34'],\n",
    "                           ccl_obj.responses_dict['G', 'L', 'G', 'G']['dpk12'], atol=0, rtol=1e-5)\n",
    "        assert np.allclose(ccl_obj.responses_dict['L', 'L', 'L', 'L']['dpk34'],\n",
    "                           ccl_obj.responses_dict['L', 'L', 'L', 'L']['dpk12'], atol=0, rtol=1e-5)\n",
    "        assert dPmm_ddeltab.shape == dPgm_ddeltab.shape == dPgg_ddeltab.shape, 'dPab_ddeltab_hm shape mismatch'\n",
    "\n",
    "        dPmm_ddeltab_hm_func = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPmm_ddeltab_hm, method='linear')\n",
    "        dPgm_ddeltab_hm_func = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPgm_ddeltab_hm, method='linear')\n",
    "        dPgg_ddeltab_hm_func = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPgg_ddeltab_hm, method='linear')\n",
    "\n",
    "    elif covariance_cfg['Spaceborne_cfg']['which_pk_responses'] == 'separate_universe':\n",
    "\n",
    "        k_grid_resp = np.logspace(covariance_cfg['Spaceborne_cfg']['log10_k_min_resp'],\n",
    "                                  covariance_cfg['Spaceborne_cfg']['log10_k_max_resp'],\n",
    "                                  covariance_cfg['Spaceborne_cfg']['k_steps_resp'])\n",
    "        z_grid_resp = z_grid_ssc_integrands\n",
    "\n",
    "        resp_obj = responses.SpaceborneResponses(cfg=cfg, k_grid=k_grid_resp,\n",
    "                                                 z_grid=z_grid_resp,\n",
    "                                                 cosmo_ccl=ccl_obj.cosmo_ccl,\n",
    "                                                 b1_func=ccl_obj.gal_bias_func_ofz)\n",
    "        r_mm = resp_obj.compute_r1_mm()\n",
    "        resp_obj.get_rab_and_dpab_ddeltab()\n",
    "\n",
    "        r_gm = resp_obj.r1_gm\n",
    "        r_gg = resp_obj.r1_gg\n",
    "        if not covariance_cfg['Spaceborne_cfg']['include_b2']:\n",
    "            r_gm = resp_obj.r1_gm_nob2\n",
    "            r_gg = resp_obj.r1_gg_nob2\n",
    "\n",
    "            dPmm_ddeltab = resp_obj.dPmm_ddeltab\n",
    "            dPgm_ddeltab = resp_obj.dPgm_ddeltab\n",
    "            dPgg_ddeltab = resp_obj.dPgg_ddeltab\n",
    "\n",
    "    else:\n",
    "        raise ValueError('which_pk_responses must be either \"halo_model\" or \"separate_universe\"')\n",
    "\n",
    "    # ! 2. prepare integrands (d2CAB_dVddeltab) and volume element\n",
    "    k_limber = partial(cosmo_lib.k_limber, cosmo_ccl=ccl_obj.cosmo_ccl, use_h_units=use_h_units)\n",
    "    r_of_z_func = partial(cosmo_lib.ccl_comoving_distance, use_h_units=use_h_units, cosmo_ccl=ccl_obj.cosmo_ccl)\n",
    "\n",
    "    # ! divide by r(z)**2 if cl_integral_convention == 'PySSC'\n",
    "    if covariance_cfg['Spaceborne_cfg']['cl_integral_convention'] == 'PySSC':\n",
    "        r_of_z_square = r_of_z_func(z_grid_ssc_integrands) ** 2\n",
    "\n",
    "        wf_delta = ccl_obj.wf_delta_arr / r_of_z_square[:, None]\n",
    "        wf_gamma = ccl_obj.wf_gamma_arr / r_of_z_square[:, None]\n",
    "        wf_ia = ccl_obj.wf_ia_arr / r_of_z_square[:, None]\n",
    "        wf_mu = ccl_obj.wf_mu_arr / r_of_z_square[:, None]\n",
    "        wf_lensing = ccl_obj.wf_lensing_arr / r_of_z_square[:, None]\n",
    "\n",
    "    # ! compute the Pk responses(k, z) in k_limber and z_grid_ssc_integrands\n",
    "    dPmm_ddeltab_interp = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPmm_ddeltab, method='linear')\n",
    "    dPgm_ddeltab_interp = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPgm_ddeltab, method='linear')\n",
    "    dPgg_ddeltab_interp = RegularGridInterpolator((k_grid_resp, z_grid_resp), dPgg_ddeltab, method='linear')\n",
    "\n",
    "    # ! test k_max_limber vs k_max_dPk and adjust z_min_ssc_integrands accordingly\n",
    "    k_max_resp = np.max(k_grid_resp)\n",
    "    ell_grid = ell_dict['ell_3x2pt']\n",
    "    kmax_limber = cosmo_lib.get_kmax_limber(ell_grid, z_grid_ssc_integrands, use_h_units, ccl_obj.cosmo_ccl)\n",
    "\n",
    "    z_grid_ssc_integrands_test = deepcopy(z_grid_ssc_integrands)\n",
    "    while kmax_limber > k_max_resp:\n",
    "        print(f'kmax_limber > k_max_dPk ({kmax_limber:.2f} {k_txt_label} > {k_max_resp:.2f} {k_txt_label}): '\n",
    "              f'Increasing z_min until kmax_limber < k_max_dPk. Alternetively, increase k_max_dPk or decrease ell_max.')\n",
    "        z_grid_ssc_integrands_test = z_grid_ssc_integrands_test[1:]\n",
    "        kmax_limber = cosmo_lib.get_kmax_limber(\n",
    "            ell_grid, z_grid_ssc_integrands_test, use_h_units, ccl_obj.cosmo_ccl)\n",
    "        print(f'New z_min = {z_grid_ssc_integrands_test[0]:.3f}')\n",
    "\n",
    "    dPmm_ddeltab_klimb = np.array(\n",
    "        [dPmm_ddeltab_interp((k_limber(ell_val, z_grid_ssc_integrands), z_grid_ssc_integrands)) for ell_val in\n",
    "            ell_dict['ell_WL']])\n",
    "    dPgm_ddeltab_klimb = np.array(\n",
    "        [dPgm_ddeltab_interp((k_limber(ell_val, z_grid_ssc_integrands), z_grid_ssc_integrands)) for ell_val in\n",
    "            ell_dict['ell_XC']])\n",
    "    dPgg_ddeltab_klimb = np.array(\n",
    "        [dPgg_ddeltab_interp((k_limber(ell_val, z_grid_ssc_integrands), z_grid_ssc_integrands)) for ell_val in\n",
    "            ell_dict['ell_GC']])\n",
    "\n",
    "    # ! volume element\n",
    "    cl_integral_prefactor = cosmo_lib.cl_integral_prefactor(z_grid_ssc_integrands,\n",
    "                                                            covariance_cfg['Spaceborne_cfg']['cl_integral_convention'],\n",
    "                                                            use_h_units=use_h_units,\n",
    "                                                            cosmo_ccl=ccl_obj.cosmo_ccl)\n",
    "\n",
    "    # ! observable densities\n",
    "    d2CLL_dVddeltab = np.einsum('zi,zj,Lz->Lijz', wf_lensing, wf_lensing, dPmm_ddeltab_klimb)\n",
    "    d2CGL_dVddeltab = \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_delta, wf_lensing, dPgm_ddeltab_klimb) + \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_mu, wf_lensing, dPmm_ddeltab_klimb)\n",
    "    d2CGG_dVddeltab = \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_delta, wf_delta, dPgg_ddeltab_klimb) + \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_delta, wf_mu, dPgm_ddeltab_klimb) + \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_mu, wf_delta, dPgm_ddeltab_klimb) + \\\n",
    "        np.einsum('zi,zj,Lz->Lijz', wf_mu, wf_mu, dPmm_ddeltab_klimb)\n",
    "\n",
    "    # ! 3. Compute/load/save sigma2_b\n",
    "    k_grid_sigma2 = np.logspace(covariance_cfg['Spaceborne_cfg']['log10_k_min_sigma2'],\n",
    "                                covariance_cfg['Spaceborne_cfg']['log10_k_max_sigma2'],\n",
    "                                covariance_cfg['Spaceborne_cfg']['k_steps_sigma2'])\n",
    "    which_sigma2_B = covariance_cfg['Spaceborne_cfg']['which_sigma2_B']\n",
    "\n",
    "    sigma2_b_path = covariance_cfg['Spaceborne_cfg']['sigma2_b_path']\n",
    "    sigma2_b_filename = covariance_cfg['Spaceborne_cfg']['sigma2_b_filename']\n",
    "    if covariance_cfg['Spaceborne_cfg']['load_precomputed_sigma2_b']:\n",
    "        # TODO define a suitable interpolator if the zgrid doesn't match\n",
    "        sigma2_b_dict = np.load(f'{sigma2_b_path}/{sigma2_b_filename}', allow_pickle=True).item()\n",
    "        cfg_sigma2_b = sigma2_b_dict['cfg']  # TODO check that the cfg matches the one\n",
    "        sigma2_b = sigma2_b_dict['sigma2_b']\n",
    "    else:\n",
    "        # TODO input ell and cl mask\n",
    "        print('Computing sigma2_b...')\n",
    "        sigma2_b = np.zeros((len(z_grid_ssc_integrands), len(z_grid_ssc_integrands)))\n",
    "        for z2_idx, z2 in enumerate(tqdm(z_grid_ssc_integrands)):\n",
    "            sigma2_b[:, z2_idx] = sigma2_SSC.sigma2_func_vectorized(\n",
    "                z1_arr=z_grid_ssc_integrands,\n",
    "                z2=z2, k_grid_sigma2=k_grid_sigma2,\n",
    "                cosmo_ccl=ccl_obj.cosmo_ccl,\n",
    "                which_sigma2_B=which_sigma2_B,\n",
    "                ell_mask=None, cl_mask=None)\n",
    "\n",
    "        if covariance_cfg['Spaceborne_cfg']['save_sigma2_b']:\n",
    "            sigma2_b_dict_tosave = {\n",
    "                'cfg': cfg,\n",
    "                'sigma2_b': sigma2_b,\n",
    "            }\n",
    "            np.save(f'{sigma2_b_path}/{sigma2_b_filename}', sigma2_b_dict_tosave, allow_pickle=True)\n",
    "\n",
    "    mm.matshow(sigma2_b, log=True, abs_val=True, title=r'$\\sigma^2_B(z_1, z_2)$')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.semilogy(z_grid_ssc_integrands, np.diag(sigma2_b))\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel(r'$\\sigma^2_B(z_1=z_2)$')\n",
    "    plt.close()\n",
    "\n",
    "    z1_idx = len(z_grid_ssc_integrands) // 2\n",
    "    z1_val = z_grid_ssc_integrands[z1_idx]\n",
    "    plt.figure()\n",
    "    plt.plot(z_grid_ssc_integrands, sigma2_b[z1_idx, :])\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel(r'$\\sigma^2_B(z_2, z1=%.3f)$' % z1_val)\n",
    "    plt.close()\n",
    "\n",
    "    # ! 4. Perform the integration calling the Julia module\n",
    "    print('Performing the 2D integral in Julia...')\n",
    "    start = time.perf_counter()\n",
    "    cov_ssc_3x2pt_dict_8D = covmat_utils.ssc_integral_julia(d2CLL_dVddeltab=d2CLL_dVddeltab,\n",
    "                                                            d2CGL_dVddeltab=d2CGL_dVddeltab,\n",
    "                                                            d2CGG_dVddeltab=d2CGG_dVddeltab,\n",
    "                                                            ind_auto=ind_auto, ind_cross=ind_cross,\n",
    "                                                            cl_integral_prefactor=cl_integral_prefactor, sigma2=sigma2_b,\n",
    "                                                            z_grid=z_grid_ssc_integrands,\n",
    "                                                            integration_type=covariance_cfg['Spaceborne_cfg']['integration_type'],\n",
    "                                                            probe_ordering=probe_ordering,\n",
    "                                                            num_threads=general_cfg['num_threads'])\n",
    "    print('SSC computed with Julia in {:.2f} s'.format(time.perf_counter() - start))\n",
    "\n",
    "    # If the mask is not passed to sigma2_b, we need to divide by fsky\n",
    "    if which_sigma2_B == 'full-curved-sky':\n",
    "        for key in cov_ssc_3x2pt_dict_8D.keys():\n",
    "            cov_ssc_3x2pt_dict_8D[key] /= covariance_cfg['fsky']\n",
    "    elif which_sigma2_B == 'mask':\n",
    "        raise NotImplementedError('Not implemented yet, but very easy to do')\n",
    "    else:\n",
    "        raise ValueError(f'which_sigma2_B must be either \"full-curved-sky\" or \"mask\"')\n",
    "\n",
    "    # save the covariance blocks\n",
    "    # ! note that these files already account for the sky fraction!!\n",
    "    # TODO fsky suffix in cov name should be added only in this case... or not? the other covariance files don't have this...\n",
    "    for key in cov_ssc_3x2pt_dict_8D.keys():\n",
    "        probe_a, probe_b, probe_c, probe_d = key\n",
    "        if str.join('', (probe_a, probe_b, probe_c, probe_d)) not in ['GLLL', 'GGLL', 'GGGL']:\n",
    "            np.savez_compressed(\n",
    "                f'{cov_folder_sb}/{cov_sb_filename.format(probe_a=probe_a,\n",
    "                                                          probe_b=probe_b, probe_c=probe_c, probe_d=probe_d)}',\n",
    "                cov_ssc_3x2pt_dict_8D[key])\n",
    "\n",
    "# this is not very elegant, find a better solution\n",
    "if covariance_cfg['ng_cov_code'] == 'Spaceborne':\n",
    "    covariance_cfg['cov_ssc_3x2pt_dict_8D_sb'] = cov_ssc_3x2pt_dict_8D\n",
    "\n",
    "print('SSC computed with Spaceborne')\n",
    "# TODO integrate this with Spaceborne_covg\n",
    "\n",
    "symmetrize_output_dict = {\n",
    "    ('L', 'L'): False,\n",
    "    ('G', 'L'): False,\n",
    "    ('L', 'G'): False,\n",
    "    ('G', 'G'): False,\n",
    "}\n",
    "cov_ssc_sb_3x2pt_dict_10D = mm.cov_3x2pt_dict_8d_to_10d(\n",
    "    covariance_cfg['cov_ssc_3x2pt_dict_8D_sb'], nbl_3x2pt, zbins, ind_dict, probe_ordering, symmetrize_output_dict)\n",
    "cov_ssc_sb_3x2pt_10D = mm.cov_10D_dict_to_array(cov_ssc_sb_3x2pt_dict_10D, nbl_3x2pt, zbins, n_probes)\n",
    "cov_3x2pt_SS_10D = cov_ssc_sb_3x2pt_10D\n",
    "\n",
    "cov_3x2pt_SS_4D = mm.cov_3x2pt_10D_to_4D(cov_3x2pt_SS_10D, probe_ordering, nbl_3x2pt, zbins, ind.copy(), gl_or_lg)\n",
    "\n",
    "# to see the individual covariance blocks\n",
    "cov_3x2pt_SS_2D = mm.cov_4D_to_2DCLOE_3x2pt(cov_3x2pt_SS_4D, block_index='ell', zbins=zbins)\n",
    "\n",
    "mm.matshow(cov_3x2pt_SS_2D, log=True, abs_val=True, title='SSC 2D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e237a4",
   "metadata": {},
   "source": [
    "#### NG covariance with OneCovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1cf3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "if covariance_cfg['ng_cov_code'] == 'OneCovariance' or \\\n",
    "    (covariance_cfg['ng_cov_code'] == 'Spaceborne' and\n",
    "        not covariance_cfg['OneCovariance_cfg']['use_OneCovariance_SSC']):\n",
    "\n",
    "    # * 1. save ingredients in ascii format\n",
    "    oc_path = covariance_cfg['OneCovariance_cfg']['onecovariance_folder'].format(ROOT=ROOT, **variable_specs)\n",
    "    if not os.path.exists(oc_path):\n",
    "        os.makedirs(oc_path)\n",
    "\n",
    "    nofz_ascii_filename = nofz_filename.replace('.dat', f'_dzshifts{shift_nz}.ascii')\n",
    "    nofz_tosave = np.column_stack((zgrid_nz, n_of_z))\n",
    "    np.savetxt(f'{oc_path}/{nofz_ascii_filename}', nofz_tosave)\n",
    "\n",
    "    cl_ll_ascii_filename = f'Cell_ll_SPV3_nbl{nbl_3x2pt}'\n",
    "    cl_gl_ascii_filename = f'Cell_gl_SPV3_nbl{nbl_3x2pt}'\n",
    "    cl_gg_ascii_filename = f'Cell_gg_SPV3_nbl{nbl_3x2pt}'\n",
    "    mm.write_cl_ascii(oc_path, cl_ll_ascii_filename, cl_3x2pt_5d[0, 0, ...], ell_dict['ell_3x2pt'], zbins)\n",
    "    mm.write_cl_ascii(oc_path, cl_gl_ascii_filename, cl_3x2pt_5d[1, 0, ...], ell_dict['ell_3x2pt'], zbins)\n",
    "    mm.write_cl_ascii(oc_path, cl_gg_ascii_filename, cl_3x2pt_5d[1, 1, ...], ell_dict['ell_3x2pt'], zbins)\n",
    "\n",
    "    gal_bias_ascii_filename = f'{oc_path}/gal_bias_table_{general_cfg[\"which_forecast\"]}.ascii'\n",
    "    ccl_obj.save_gal_bias_table_ascii(z_grid_ssc_integrands, gal_bias_ascii_filename)\n",
    "\n",
    "    ascii_filenames_dict = {\n",
    "        'cl_ll_ascii_filename': cl_ll_ascii_filename,\n",
    "        'cl_gl_ascii_filename': cl_gl_ascii_filename,\n",
    "        'cl_gg_ascii_filename': cl_gg_ascii_filename,\n",
    "        'gal_bias_ascii_filename': gal_bias_ascii_filename,\n",
    "        'nofz_ascii_filename': nofz_ascii_filename,\n",
    "    }\n",
    "\n",
    "    # * 2. compute cov using the onecovariance interface class\n",
    "    print('Start NG cov computation with OneCovariance...')\n",
    "\n",
    "    # TODO this should be defined globally...\n",
    "    symmetrize_output_dict = {\n",
    "        ('L', 'L'): False,\n",
    "        ('G', 'L'): False,\n",
    "        ('L', 'G'): False,\n",
    "        ('G', 'G'): False,\n",
    "    }\n",
    "\n",
    "    oc_obj = oc_interface.OneCovarianceInterface(ROOT, cfg, variable_specs)\n",
    "    oc_obj.build_save_oc_ini(ascii_filenames_dict, print_ini=True)\n",
    "\n",
    "    oc_obj.call_onecovariance()\n",
    "    oc_obj.reshape_oc_output(variable_specs, ind_dict, symmetrize_output_dict)\n",
    "\n",
    "    oc_obj.cov_g_oc_3x2pt_10D = oc_obj.oc_output_to_dict_or_array(\n",
    "        'G', '10D_array', ind_dict, symmetrize_output_dict)\n",
    "    oc_obj.cov_ssc_oc_3x2pt_10D = oc_obj.oc_output_to_dict_or_array(\n",
    "        'SSC', '10D_array', ind_dict, symmetrize_output_dict)\n",
    "    oc_obj.cov_cng_oc_3x2pt_10D = oc_obj.oc_output_to_dict_or_array(\n",
    "        'cNG', '10D_array', ind_dict, symmetrize_output_dict)\n",
    "\n",
    "    print('Time taken to compute OC: {:.2f} m'.format((time.perf_counter() - start_time) / 60))\n",
    "\n",
    "else:\n",
    "    oc_obj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! standard method for cl_ell_cuts: get the idxs to delete for the flattened 1d cls\n",
    "if general_cfg['center_or_min'] == 'center':\n",
    "    prefix = 'ell'\n",
    "elif general_cfg['center_or_min'] == 'min':\n",
    "    prefix = 'ell_edges'\n",
    "else:\n",
    "    raise ValueError('general_cfg[\"center_or_min\"] should be either \"center\" or \"min\"')\n",
    "\n",
    "ell_dict['idxs_to_delete_dict'] = {\n",
    "    'LL': ell_utils.get_idxs_to_delete(ell_dict[f'{prefix}_WL'], ell_cuts_dict['LL'], is_auto_spectrum=True, zbins=zbins),\n",
    "    'GG': ell_utils.get_idxs_to_delete(ell_dict[f'{prefix}_GC'], ell_cuts_dict['GG'], is_auto_spectrum=True, zbins=zbins),\n",
    "    'WA': ell_utils.get_idxs_to_delete(ell_dict[f'{prefix}_WA'], ell_cuts_dict['LL'], is_auto_spectrum=True, zbins=zbins),\n",
    "    'GL': ell_utils.get_idxs_to_delete(ell_dict[f'{prefix}_XC'], ell_cuts_dict['GL'], is_auto_spectrum=False, zbins=zbins),\n",
    "    'LG': ell_utils.get_idxs_to_delete(ell_dict[f'{prefix}_XC'], ell_cuts_dict['LG'], is_auto_spectrum=False, zbins=zbins),\n",
    "    '3x2pt': ell_utils.get_idxs_to_delete_3x2pt(ell_dict[f'{prefix}_3x2pt'], ell_cuts_dict, zbins, covariance_cfg)\n",
    "}\n",
    "\n",
    "# ! 3d cl ell cuts (*after* BNT!!)\n",
    "if general_cfg['cl_ell_cuts']:\n",
    "    cl_ll_3d = cl_utils.cl_ell_cut(cl_ll_3d, ell_dict['ell_WL'], ell_cuts_dict['LL'])\n",
    "    cl_gg_3d = cl_utils.cl_ell_cut(cl_gg_3d, ell_dict['ell_GC'], ell_cuts_dict['GG'])\n",
    "    cl_3x2pt_5d = cl_utils.cl_ell_cut_3x2pt(cl_3x2pt_5d, ell_cuts_dict, ell_dict['ell_3x2pt'])\n",
    "\n",
    "# TODO delete this\n",
    "\n",
    "# store cls and responses in a dictionary\n",
    "cl_dict_3D = {\n",
    "    'cl_LL_3D': cl_ll_3d,\n",
    "    'cl_GG_3D': cl_gg_3d,\n",
    "    'cl_WA_3D': cl_wa_3d,\n",
    "    'cl_3x2pt_5D': cl_3x2pt_5d}\n",
    "\n",
    "rl_dict_3D = {\n",
    "    'rl_LL_3D': np.ones_like(cl_ll_3d),\n",
    "    'rl_GG_3D': np.ones_like(cl_gg_3d),\n",
    "    'rl_WA_3D': np.ones_like(cl_wa_3d),\n",
    "    'rl_3x2pt_5D': np.ones_like(cl_3x2pt_5d)}\n",
    "\n",
    "# this is again to test against ccl cls\n",
    "general_cfg['cl_ll_3d'] = cl_ll_3d\n",
    "general_cfg['cl_gl_3d'] = cl_gl_3d\n",
    "general_cfg['cl_gg_3d'] = cl_gg_3d\n",
    "\n",
    "\n",
    "# ! compute covariance matrix\n",
    "cov_dict = covmat_utils.compute_cov(general_cfg, covariance_cfg,\n",
    "                                    ell_dict, delta_dict, cl_dict_3D, rl_dict_3D,\n",
    "                                    Sijkl=None, BNT_matrix=bnt_matrix, oc_obj=oc_obj)\n",
    "print('Finished in {:.2f} minutes'.format((time.perf_counter() - script_start_time) / 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceborne-dav",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
